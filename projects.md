---
layout: page
title: Projects
permalink: /projects/
---

**Is AI as Racist as We Think? Contextualizing Bias in Human and Large Language Model Criminal Judgments**
*(2025; ongoing)*

A matched-guise experimental design to compare professional human judgments and commercially available LLMs on identical decision-making tasks, with a focus on assessing criminal guilt and sentencing severity from controlled case descriptions to examine how linguistic cues shape divergence in reasoning across biological and probabilistic models

**Learning When to Ask: Reducing Hallucinations in LLM Coding Agents**
*(2026; ongoing; final project for CS 229: Machine Learning)*

LLM-based coding agents frequently hallucinate incorrect APIs, nonexistent files, or invalid logic when operating under incomplete context. This project frames tool usage as a decision-making problem under uncertainty, training agents to learn when to request additional information rather than guess. Using supervised and reinforcement learning approaches grounded in uncertainty signals, the goal is to reduce hallucinations while preserving task efficiency in real-world programming environments.

**Provable Limits of Expressivity of Transformers**
*(2026; ongoing; final project for CS 254: Complexity Theory)*

What is the circuit complexity of the functions computed by transformer encoders and decoders? How do different attention mechanisms (hard vs. soft, unique vs. averaged) affect expressiveness? Which formal language classes can transformers recognize? What is the relationship between transformer depth (fixed vs. O(log n)) and recognized language classes?
What tasks are provably impossible for transformers under standard complexity assumptions? What impossibility results hold unconditionally (e.g., via diagonalization, learning theory)? How do average-case vs. worst-case considerations explain the gap between empirical success and theoretical limitations?

