---
layout: page
title: Projects
permalink: /projects/
---

**Is AI as Racist as We Think? Contextualizing Bias in Human and Large Language Model Criminal Judgments**
*(2025; ongoing)*

A matched-guise experimental design to compare professional human judgments and commercially available LLMs on identical decision-making tasks, with a focus on assessing criminal guilt and sentencing severity from controlled case descriptions to examine how linguistic cues shape divergence in reasoning across biological and probabilistic models

**Learning When to Ask: Reducing Hallucinations in LLM Coding Agents**
*(2026; ongoing; final project for CS 229: Machine Learning)*

LLM-based coding agents frequently hallucinate incorrect APIs, nonexistent files, or invalid logic when operating under incomplete context. This project frames tool usage as a decision-making problem under uncertainty, training agents to learn when to request additional information rather than guess. Using supervised and reinforcement learning approaches grounded in uncertainty signals, the goal is to reduce hallucinations while preserving task efficiency in real-world programming environments.

**Coming Soon: Final Project for CS 254 (Complexity Theory)**
